{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fran/anaconda2/envs/nltk/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = load_files('txt_sentoken/')\n",
    "X, y = reviews.data, reviews.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'we could paraphrase michelle pfieffer\\'s character in dangerous minds and say that beyond rangoon starts with an \" a . \" \\nthat\\'s fair enough . \\nall movies , like all school children , should be given the benefit of the doubt . \\nthe chance to succeed . \\nafter all , we like to think that the right combination of talent and effort can do wonders . \\nmountains can be moved , and good movies can be made . \\nyeah right . \\nchildren fail , as do films . \\nas does director john boorman\\'s latest . \\nthe success of beyond rangoon hinges on the believability of patricia arquette ( ed wood , true romance ) as the busty westerner-in-peril wandering about 1988 burma without a passport . \\nthough we can stomach the mild plot contrivances that get her there , it\\'s a tougher task to overlook the actress . \\nshe\\'s a lightweight . \\nas the first scene ( with narration ! ) \\ndemonstrates , she doesn\\'t have * nearly * enough range for the emotions that her character--a mother fleeing the memories of a murdered husband and son--is supposed to show . \\nshe may give a stronger performance than , say , keanu reeves in a walk in the clouds , by not by much . \\nbeyond rangoon is a very physically appealing film , thanks to the practiced craftsmanship of john boorman ( deliverance , excalibur , hope and glory ) . \\nhe keeps the narrative moving , no matter how muddy the story--or the heroine--gets . \\nwhy he chose arquette remains a mystery , though . \\nmaybe he was thinking that the dramatic weight of the story would overcome any casting deficiencies . \\nbut even after an hour of half-stated political statements and murky mass killings , we * still * don\\'t know enough of what\\'s happening in this country to feel distressed for the characters or their situations . \\nempty exoticism . \\nthe technical credits in beyond rangoon are a curious mix , combining lush jungle photography with bad blue-screen work . \\nalso odd is the obvious dubbing . \\ndone to make some of the foreign characters sound less foreign ? \\nand , is it my mistake , or do the same extras keep reappearing as different soldiers ? ? \\ndoo doo doo doo . \\n[ \" twilight zone \" theme , or opinion of movie . \\nyou be the judge . ] \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(review):\n",
    "    review = review.lower() # to lower case\n",
    "    review = re.sub(r'\\W', ' ', str(review)) # removes all the non-word characters\n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ',review) # removes all the single characters\n",
    "    review = re.sub(r'^[a-z]\\s+', ' ',review) # removes all the single characters\n",
    "    review = re.sub(r'\\s+', ' ', review) # removes all the extra spaces\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(map(process_data, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' we could paraphrase michelle pfieffer character in dangerous minds and say that beyond rangoon starts with an nthat fair enough nall movies like all school children should be given the benefit of the doubt nthe chance to succeed nafter all we like to think that the right combination of talent and effort can do wonders nmountains can be moved and good movies can be made nyeah right nchildren fail as do films nas does director john boorman latest nthe success of beyond rangoon hinges on the believability of patricia arquette ed wood true romance as the busty westerner in peril wandering about 1988 burma without passport nthough we can stomach the mild plot contrivances that get her there it a tougher task to overlook the actress nshe a lightweight nas the first scene with narration ndemonstrates she doesn have nearly enough range for the emotions that her character mother fleeing the memories of murdered husband and son is supposed to show nshe may give stronger performance than say keanu reeves in walk in the clouds by not by much nbeyond rangoon is very physically appealing film thanks to the practiced craftsmanship of john boorman deliverance excalibur hope and glory nhe keeps the narrative moving no matter how muddy the story or the heroine gets nwhy he chose arquette remains mystery though nmaybe he was thinking that the dramatic weight of the story would overcome any casting deficiencies nbut even after an hour of half stated political statements and murky mass killings we still don know enough of what happening in this country to feel distressed for the characters or their situations nempty exoticism nthe technical credits in beyond rangoon are curious mix combining lush jungle photography with bad blue screen work nalso odd is the obvious dubbing ndone to make some of the foreign characters sound less foreign nand is it my mistake or do the same extras keep reappearing as different soldiers ndoo doo doo doo twilight zone theme or opinion of movie nyou be the judge '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the BOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 2000, \n",
    "                             min_df = 3, \n",
    "                             max_df = 0.6, \n",
    "                             stop_words = stopwords.words('english'))\n",
    "\n",
    "X = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 2, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the TF-IDF Model from the BOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "X = transformer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.06887219, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.05959645, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.06582811, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the TF-IDF model directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(max_features = 2000, \n",
    "#                              min_df = 3, \n",
    "#                              max_df = 0.6, \n",
    "#                              stop_words = stopwords.words('english'))\n",
    "\n",
    "# X = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classifier using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.83       319\n",
      "          1       0.86      0.81      0.83       341\n",
      "\n",
      "avg / total       0.83      0.83      0.83       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[274  45]\n",
      " [ 65 276]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
