{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import heapq\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from content import paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gets the top 100 frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nltk.sent_tokenize(paragraph)\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = dataset[i].lower()\n",
    "    dataset[i] = re.sub(r'\\W', ' ', dataset[i])\n",
    "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {}\n",
    "for data in dataset:\n",
    "    words = nltk.word_tokenize(data)\n",
    "    for word in words:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = heapq.nlargest(100, word2count, key=word2count.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build the TF-IDF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TF (Term Frequency) = Occurrences of a word in a document / Words in that document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = {}\n",
    "for word in freq_words:\n",
    "    sen_tf = []\n",
    "    for data in dataset:\n",
    "        words = nltk.word_tokenize(data)\n",
    "        frequency = 0\n",
    "        for w in words:\n",
    "            if word == w:\n",
    "                frequency += 1\n",
    "        tf_word = frequency/len(words)\n",
    "        sen_tf.append(tf_word)\n",
    "    tf_matrix[word] = sen_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.1,\n",
       " 0.2,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.043478260869565216,\n",
       " 0.0,\n",
       " 0.1,\n",
       " 0.06666666666666667,\n",
       " 0.05263157894736842,\n",
       " 0.0,\n",
       " 0.05,\n",
       " 0.10638297872340426,\n",
       " 0.045454545454545456,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. IDF (Inverse Document Frequency) = log(Documents / Documents containing the world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_idfs = {}\n",
    "for word in freq_words:\n",
    "    sen_count = 0\n",
    "    for data in dataset:\n",
    "        if word in nltk.word_tokenize(data):\n",
    "            sen_count += 1\n",
    "    word_idfs[word] = np.log(len(dataset)/(1 + sen_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.6466271649250525,\n",
       " 'to': 0.5596157879354227,\n",
       " 'you': 0.7419373447293773,\n",
       " 'of': 1.0986122886681098,\n",
       " 'for': 1.0986122886681098,\n",
       " 'this': 0.7419373447293773,\n",
       " 'thank': 0.8472978603872037,\n",
       " 'and': 0.965080896043587,\n",
       " 'i': 1.0986122886681098,\n",
       " 'my': 1.4350845252893227,\n",
       " 'all': 1.4350845252893227,\n",
       " 'in': 1.6582280766035324,\n",
       " 'be': 1.4350845252893227,\n",
       " 'who': 1.9459101490553132,\n",
       " 'world': 1.6582280766035324,\n",
       " 'very': 1.6582280766035324,\n",
       " 'have': 1.6582280766035324,\n",
       " 'by': 1.6582280766035324,\n",
       " 'we': 1.6582280766035324,\n",
       " 'our': 1.6582280766035324,\n",
       " 'is': 1.9459101490553132,\n",
       " 'not': 1.6582280766035324,\n",
       " 'people': 1.9459101490553132,\n",
       " 'out': 1.9459101490553132,\n",
       " 'so': 1.9459101490553132,\n",
       " 'much': 1.9459101490553132,\n",
       " 'year': 1.9459101490553132,\n",
       " 'revenant': 1.9459101490553132,\n",
       " 'was': 1.9459101490553132,\n",
       " 'off': 1.9459101490553132,\n",
       " 'tom': 1.9459101490553132,\n",
       " 'your': 2.3513752571634776,\n",
       " 'screen': 2.3513752571634776,\n",
       " 'a': 1.9459101490553132,\n",
       " 'entire': 1.9459101490553132,\n",
       " 'would': 1.9459101490553132,\n",
       " 'just': 1.9459101490553132,\n",
       " 's': 1.9459101490553132,\n",
       " 'collectively': 1.9459101490553132,\n",
       " 'planet': 1.9459101490553132,\n",
       " 'it': 1.9459101490553132,\n",
       " 'most': 1.9459101490553132,\n",
       " 'need': 1.9459101490553132,\n",
       " 'do': 1.9459101490553132,\n",
       " 'speak': 2.3513752571634776,\n",
       " 'billions': 2.3513752571634776,\n",
       " 'there': 1.9459101490553132,\n",
       " 'children': 2.3513752571634776,\n",
       " 'tonight': 1.9459101490553132,\n",
       " 'take': 1.9459101490553132,\n",
       " 'granted': 1.9459101490553132,\n",
       " 'academy': 2.3513752571634776,\n",
       " 'room': 2.3513752571634776,\n",
       " 'congratulate': 2.3513752571634776,\n",
       " 'other': 2.3513752571634776,\n",
       " 'incredible': 2.3513752571634776,\n",
       " 'nominees': 2.3513752571634776,\n",
       " 'product': 2.3513752571634776,\n",
       " 'tireless': 2.3513752571634776,\n",
       " 'efforts': 2.3513752571634776,\n",
       " 'an': 2.3513752571634776,\n",
       " 'unbelievable': 2.3513752571634776,\n",
       " 'cast': 2.3513752571634776,\n",
       " 'crew': 2.3513752571634776,\n",
       " 'first': 2.3513752571634776,\n",
       " 'brother': 2.3513752571634776,\n",
       " 'endeavor': 2.3513752571634776,\n",
       " 'mr': 2.3513752571634776,\n",
       " 'hardy': 2.3513752571634776,\n",
       " 'talent': 2.3513752571634776,\n",
       " 'on': 2.3513752571634776,\n",
       " 'can': 2.3513752571634776,\n",
       " 'only': 2.3513752571634776,\n",
       " 'surpassed': 2.3513752571634776,\n",
       " 'friendship': 2.3513752571634776,\n",
       " 'creating': 2.3513752571634776,\n",
       " 't': 2.3513752571634776,\n",
       " 'ranscendent': 2.3513752571634776,\n",
       " 'cinematic': 2.3513752571634776,\n",
       " 'experience': 2.3513752571634776,\n",
       " 'everybody': 2.3513752571634776,\n",
       " 'at': 2.3513752571634776,\n",
       " 'fox': 2.3513752571634776,\n",
       " 'new': 2.3513752571634776,\n",
       " 'regency': 2.3513752571634776,\n",
       " 'team': 2.3513752571634776,\n",
       " 'everyone': 2.3513752571634776,\n",
       " 'from': 2.3513752571634776,\n",
       " 'onset': 2.3513752571634776,\n",
       " 'career': 2.3513752571634776,\n",
       " 'parents': 2.3513752571634776,\n",
       " 'none': 2.3513752571634776,\n",
       " 'possible': 2.3513752571634776,\n",
       " 'without': 2.3513752571634776,\n",
       " 'friends': 2.3513752571634776,\n",
       " 'love': 2.3513752571634776,\n",
       " 'dearly': 2.3513752571634776,\n",
       " 'know': 2.3513752571634776,\n",
       " 'are': 2.3513752571634776,\n",
       " 'lastly': 2.3513752571634776}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. TF * IDF calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = []\n",
    "for word in tf_matrix.keys():\n",
    "    tfidf = []\n",
    "    for value in tf_matrix[word]:\n",
    "        score = value * word_idfs[word]\n",
    "        tfidf.append(score)\n",
    "    tfidf_matrix.append(tfidf)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.transpose(), columns=freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>you</th>\n",
       "      <th>of</th>\n",
       "      <th>for</th>\n",
       "      <th>this</th>\n",
       "      <th>thank</th>\n",
       "      <th>and</th>\n",
       "      <th>i</th>\n",
       "      <th>my</th>\n",
       "      <th>...</th>\n",
       "      <th>parents</th>\n",
       "      <th>none</th>\n",
       "      <th>possible</th>\n",
       "      <th>without</th>\n",
       "      <th>friends</th>\n",
       "      <th>love</th>\n",
       "      <th>dearly</th>\n",
       "      <th>know</th>\n",
       "      <th>are</th>\n",
       "      <th>lastly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129325</td>\n",
       "      <td>0.111923</td>\n",
       "      <td>0.148387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062180</td>\n",
       "      <td>0.164875</td>\n",
       "      <td>0.122068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082437</td>\n",
       "      <td>0.094144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064663</td>\n",
       "      <td>0.055962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.129325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        the        to       you        of  for      this     thank       and  \\\n",
       "0  0.000000  0.000000  0.123656  0.000000  0.0  0.000000  0.141216  0.000000   \n",
       "1  0.129325  0.111923  0.148387  0.000000  0.0  0.000000  0.169460  0.000000   \n",
       "2  0.000000  0.062180  0.164875  0.122068  0.0  0.082437  0.094144  0.000000   \n",
       "3  0.064663  0.055962  0.000000  0.000000  0.0  0.074194  0.000000  0.000000   \n",
       "4  0.129325  0.000000  0.000000  0.146482  0.0  0.000000  0.000000  0.064339   \n",
       "\n",
       "          i   my   ...    parents  none  possible  without  friends  love  \\\n",
       "0  0.000000  0.0   ...        0.0   0.0       0.0      0.0      0.0   0.0   \n",
       "1  0.000000  0.0   ...        0.0   0.0       0.0      0.0      0.0   0.0   \n",
       "2  0.000000  0.0   ...        0.0   0.0       0.0      0.0      0.0   0.0   \n",
       "3  0.109861  0.0   ...        0.0   0.0       0.0      0.0      0.0   0.0   \n",
       "4  0.000000  0.0   ...        0.0   0.0       0.0      0.0      0.0   0.0   \n",
       "\n",
       "   dearly  know  are  lastly  \n",
       "0     0.0   0.0  0.0     0.0  \n",
       "1     0.0   0.0  0.0     0.0  \n",
       "2     0.0   0.0  0.0     0.0  \n",
       "3     0.0   0.0  0.0     0.0  \n",
       "4     0.0   0.0  0.0     0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
