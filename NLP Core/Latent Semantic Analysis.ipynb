{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fran/anaconda2/envs/nltk/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"The amount of pollution is increasing day by day\",\n",
    "           \"The concert was just great\",\n",
    "           \"I love to see Gordon Ramsay cook\",\n",
    "           \"Google is introducing a new technology\",\n",
    "           \"AI Robots are examples of great technology present today\",\n",
    "           \"All of us were singing in the concert\",\n",
    "           \"We have launch campaigns to stop pollution and global warming\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower-casing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [line.lower() for line in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 41)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai',\n",
       " 'all',\n",
       " 'amount',\n",
       " 'and',\n",
       " 'are',\n",
       " 'by',\n",
       " 'campaigns',\n",
       " 'concert',\n",
       " 'cook',\n",
       " 'day',\n",
       " 'examples',\n",
       " 'global',\n",
       " 'google',\n",
       " 'gordon',\n",
       " 'great',\n",
       " 'have',\n",
       " 'in',\n",
       " 'increasing',\n",
       " 'introducing',\n",
       " 'is',\n",
       " 'just',\n",
       " 'launch',\n",
       " 'love',\n",
       " 'new',\n",
       " 'of',\n",
       " 'pollution',\n",
       " 'present',\n",
       " 'ramsay',\n",
       " 'robots',\n",
       " 'see',\n",
       " 'singing',\n",
       " 'stop',\n",
       " 'technology',\n",
       " 'the',\n",
       " 'to',\n",
       " 'today',\n",
       " 'us',\n",
       " 'warming',\n",
       " 'was',\n",
       " 'we',\n",
       " 'were']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.32642545, 0.        , 0.        ,\n",
       "        0.32642545, 0.        , 0.        , 0.        , 0.65285089,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.32642545, 0.        , 0.27096115,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23160861,\n",
       "        0.27096115, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23160861, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 33)\t0.231608612212116\n",
      "  (0, 2)\t0.326425447033964\n",
      "  (0, 24)\t0.231608612212116\n",
      "  (0, 25)\t0.270961154226111\n",
      "  (0, 19)\t0.270961154226111\n",
      "  (0, 17)\t0.326425447033964\n",
      "  (0, 9)\t0.652850894067928\n",
      "  (0, 5)\t0.326425447033964\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=4, n_iter=100,\n",
       "       random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components = 4, n_iter = 100) # n_components => number of concepts you wanna find in the data\n",
    "lsa.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 41)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12230514, 0.17593921, 0.11986219, 0.02391177, 0.12230514,\n",
       "       0.11986219, 0.02391177, 0.33986475, 0.00740591, 0.23972439,\n",
       "       0.12230514, 0.02391177, 0.09746251, 0.00740591, 0.29534387,\n",
       "       0.02391177, 0.17593921, 0.11986219, 0.09746251, 0.18039817,\n",
       "       0.23349403, 0.02391177, 0.00740591, 0.09746251, 0.29665909,\n",
       "       0.11934473, 0.12230514, 0.00740591, 0.12230514, 0.00740591,\n",
       "       0.17593921, 0.02391177, 0.18242602, 0.37555093, 0.02599636,\n",
       "       0.12230514, 0.17593921, 0.02391177, 0.23349403, 0.02391177,\n",
       "       0.17593921])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lsa.components_, index=['Concept ' + str(i+1) for i in range(4)] , columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept 1</th>\n",
       "      <th>Concept 2</th>\n",
       "      <th>Concept 3</th>\n",
       "      <th>Concept 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>0.122305</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.125254</td>\n",
       "      <td>-0.195291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.175939</td>\n",
       "      <td>-0.079465</td>\n",
       "      <td>-0.124206</td>\n",
       "      <td>0.040094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>0.119862</td>\n",
       "      <td>0.082287</td>\n",
       "      <td>0.036614</td>\n",
       "      <td>0.196403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.203802</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>0.122305</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.125254</td>\n",
       "      <td>-0.195291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>0.119862</td>\n",
       "      <td>0.082287</td>\n",
       "      <td>0.036614</td>\n",
       "      <td>0.196403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaigns</th>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.203802</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concert</th>\n",
       "      <td>0.339865</td>\n",
       "      <td>-0.165508</td>\n",
       "      <td>-0.218994</td>\n",
       "      <td>-0.042342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cook</th>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.223737</td>\n",
       "      <td>-0.130714</td>\n",
       "      <td>-0.226291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.239724</td>\n",
       "      <td>0.164575</td>\n",
       "      <td>0.073227</td>\n",
       "      <td>0.392806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>examples</th>\n",
       "      <td>0.122305</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.125254</td>\n",
       "      <td>-0.195291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global</th>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.203802</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0.097463</td>\n",
       "      <td>0.121486</td>\n",
       "      <td>0.318285</td>\n",
       "      <td>-0.005104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gordon</th>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.223737</td>\n",
       "      <td>-0.130714</td>\n",
       "      <td>-0.226291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.295344</td>\n",
       "      <td>-0.097159</td>\n",
       "      <td>-0.011922</td>\n",
       "      <td>-0.237733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.203802</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.175939</td>\n",
       "      <td>-0.079465</td>\n",
       "      <td>-0.124206</td>\n",
       "      <td>0.040094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increasing</th>\n",
       "      <td>0.119862</td>\n",
       "      <td>0.082287</td>\n",
       "      <td>0.036614</td>\n",
       "      <td>0.196403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>introducing</th>\n",
       "      <td>0.097463</td>\n",
       "      <td>0.121486</td>\n",
       "      <td>0.318285</td>\n",
       "      <td>-0.005104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0.180398</td>\n",
       "      <td>0.169149</td>\n",
       "      <td>0.294596</td>\n",
       "      <td>0.158794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>0.233494</td>\n",
       "      <td>-0.119921</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.091104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launch</th>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.203802</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.223737</td>\n",
       "      <td>-0.130714</td>\n",
       "      <td>-0.226291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.097463</td>\n",
       "      <td>0.121486</td>\n",
       "      <td>0.318285</td>\n",
       "      <td>-0.005104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.296659</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>0.029237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pollution</th>\n",
       "      <td>0.119345</td>\n",
       "      <td>0.237479</td>\n",
       "      <td>-0.041311</td>\n",
       "      <td>0.216201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>present</th>\n",
       "      <td>0.122305</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.125254</td>\n",
       "      <td>-0.195291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramsay</th>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.223737</td>\n",
       "      <td>-0.130714</td>\n",
       "      <td>-0.226291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robots</th>\n",
       "      <td>0.122305</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.125254</td>\n",
       "      <td>-0.195291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.223737</td>\n",
       "      <td>-0.130714</td>\n",
       "      <td>-0.226291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>singing</th>\n",
       "      <td>0.175939</td>\n",
       "      <td>-0.079465</td>\n",
       "      <td>-0.124206</td>\n",
       "      <td>0.040094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop</th>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.203802</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>0.182426</td>\n",
       "      <td>0.103229</td>\n",
       "      <td>0.368175</td>\n",
       "      <td>-0.166345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.375551</td>\n",
       "      <td>-0.083085</td>\n",
       "      <td>-0.161211</td>\n",
       "      <td>0.103161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.354894</td>\n",
       "      <td>-0.180207</td>\n",
       "      <td>-0.134671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>0.122305</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.125254</td>\n",
       "      <td>-0.195291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>0.175939</td>\n",
       "      <td>-0.079465</td>\n",
       "      <td>-0.124206</td>\n",
       "      <td>0.040094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warming</th>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.203802</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>0.233494</td>\n",
       "      <td>-0.119921</td>\n",
       "      <td>-0.139616</td>\n",
       "      <td>-0.091104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>0.023912</td>\n",
       "      <td>0.203802</td>\n",
       "      <td>-0.086381</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>0.175939</td>\n",
       "      <td>-0.079465</td>\n",
       "      <td>-0.124206</td>\n",
       "      <td>0.040094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Concept 1  Concept 2  Concept 3  Concept 4\n",
       "ai            0.122305   0.002874   0.125254  -0.195291\n",
       "all           0.175939  -0.079465  -0.124206   0.040094\n",
       "amount        0.119862   0.082287   0.036614   0.196403\n",
       "and           0.023912   0.203802  -0.086381   0.064054\n",
       "are           0.122305   0.002874   0.125254  -0.195291\n",
       "by            0.119862   0.082287   0.036614   0.196403\n",
       "campaigns     0.023912   0.203802  -0.086381   0.064054\n",
       "concert       0.339865  -0.165508  -0.218994  -0.042342\n",
       "cook          0.007406   0.223737  -0.130714  -0.226291\n",
       "day           0.239724   0.164575   0.073227   0.392806\n",
       "examples      0.122305   0.002874   0.125254  -0.195291\n",
       "global        0.023912   0.203802  -0.086381   0.064054\n",
       "google        0.097463   0.121486   0.318285  -0.005104\n",
       "gordon        0.007406   0.223737  -0.130714  -0.226291\n",
       "great         0.295344  -0.097159  -0.011922  -0.237733\n",
       "have          0.023912   0.203802  -0.086381   0.064054\n",
       "in            0.175939  -0.079465  -0.124206   0.040094\n",
       "increasing    0.119862   0.082287   0.036614   0.196403\n",
       "introducing   0.097463   0.121486   0.318285  -0.005104\n",
       "is            0.180398   0.169149   0.294596   0.158794\n",
       "just          0.233494  -0.119921  -0.139616  -0.091104\n",
       "launch        0.023912   0.203802  -0.086381   0.064054\n",
       "love          0.007406   0.223737  -0.130714  -0.226291\n",
       "new           0.097463   0.121486   0.318285  -0.005104\n",
       "of            0.296659   0.004041   0.026722   0.029237\n",
       "pollution     0.119345   0.237479  -0.041311   0.216201\n",
       "present       0.122305   0.002874   0.125254  -0.195291\n",
       "ramsay        0.007406   0.223737  -0.130714  -0.226291\n",
       "robots        0.122305   0.002874   0.125254  -0.195291\n",
       "see           0.007406   0.223737  -0.130714  -0.226291\n",
       "singing       0.175939  -0.079465  -0.124206   0.040094\n",
       "stop          0.023912   0.203802  -0.086381   0.064054\n",
       "technology    0.182426   0.103229   0.368175  -0.166345\n",
       "the           0.375551  -0.083085  -0.161211   0.103161\n",
       "to            0.025996   0.354894  -0.180207  -0.134671\n",
       "today         0.122305   0.002874   0.125254  -0.195291\n",
       "us            0.175939  -0.079465  -0.124206   0.040094\n",
       "warming       0.023912   0.203802  -0.086381   0.064054\n",
       "was           0.233494  -0.119921  -0.139616  -0.091104\n",
       "we            0.023912   0.203802  -0.086381   0.064054\n",
       "were          0.175939  -0.079465  -0.124206   0.040094"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concept 1:\n",
      "('the', 0.375550932899053)\n",
      "('concert', 0.3398647517392532)\n",
      "('of', 0.29665909350149083)\n",
      "('great', 0.29534386566053683)\n",
      "('day', 0.23972438835590149)\n",
      "('just', 0.23349402804713223)\n",
      "('was', 0.23349402804713223)\n",
      "('technology', 0.18242602421743503)\n",
      "('is', 0.1803981689876796)\n",
      "('all', 0.1759392127966662)\n",
      "\n",
      "Concept 2:\n",
      "('to', 0.3548941474782012)\n",
      "('pollution', 0.23747906096178822)\n",
      "('cook', 0.2237367705446092)\n",
      "('gordon', 0.2237367705446092)\n",
      "('love', 0.2237367705446092)\n",
      "('ramsay', 0.2237367705446092)\n",
      "('see', 0.2237367705446092)\n",
      "('and', 0.20380230261581192)\n",
      "('campaigns', 0.20380230261581192)\n",
      "('global', 0.20380230261581192)\n",
      "\n",
      "Concept 3:\n",
      "('technology', 0.3681751594120383)\n",
      "('google', 0.31828506931586975)\n",
      "('introducing', 0.31828506931586975)\n",
      "('new', 0.31828506931586975)\n",
      "('is', 0.29459629228393713)\n",
      "('are', 0.12525356758256406)\n",
      "('examples', 0.12525356758256406)\n",
      "('present', 0.12525356758256406)\n",
      "('robots', 0.12525356758256406)\n",
      "('today', 0.12525356758256406)\n",
      "\n",
      "Concept 4:\n",
      "('day', 0.3928059228972394)\n",
      "('pollution', 0.21620148753224405)\n",
      "('amount', 0.19640296144861993)\n",
      "('by', 0.1964029614486197)\n",
      "('increasing', 0.1964029614486197)\n",
      "('is', 0.1587942790036928)\n",
      "('the', 0.10316082823817713)\n",
      "('campaigns', 0.06405380925965906)\n",
      "('global', 0.06405380925965906)\n",
      "('have', 0.06405380925965906)\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# Word Concept Dictionary Creation\n",
    "concept_words = {}\n",
    "\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    componentTerms = zip(terms, comp)\n",
    "    sortedTerms = sorted(componentTerms, key=lambda x: x[1], reverse=True)\n",
    "    sortedTerms = sortedTerms[:10] # grabbing the first 10 elements\n",
    "    \n",
    "    print('\\nConcept ' + str(i+1) + ':')\n",
    "    concept_words[\"Concept \" + str(i+1)] = sortedTerms\n",
    "    \n",
    "    for term in sortedTerms:\n",
    "        print(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concept 1:\n",
      "\t- the amount of pollution is increasing day by day => 1.3320569721000264\n",
      "\t- the concert was just great => 1.4777476063931076\n",
      "\t- i love to see gordon ramsay cook => 0\n",
      "\t- google is introducing a new technology => 0.3628241932051146\n",
      "\t- ai robots are examples of great technology present today => 0.7744289833794628\n",
      "\t- all of us were singing in the concert => 1.1880139909364633\n",
      "\t- we have launch campaigns to stop pollution and global warming => 0\n",
      "\n",
      "Concept 2:\n",
      "\t- the amount of pollution is increasing day by day => 0.23747906096178822\n",
      "\t- the concert was just great => 0\n",
      "\t- i love to see gordon ramsay cook => 1.473578000201247\n",
      "\t- google is introducing a new technology => 0\n",
      "\t- ai robots are examples of great technology present today => 0\n",
      "\t- all of us were singing in the concert => 0\n",
      "\t- we have launch campaigns to stop pollution and global warming => 1.203780116287425\n",
      "\n",
      "Concept 3:\n",
      "\t- the amount of pollution is increasing day by day => 0.29459629228393713\n",
      "\t- the concert was just great => 0\n",
      "\t- i love to see gordon ramsay cook => 0\n",
      "\t- google is introducing a new technology => 1.6176266596435849\n",
      "\t- ai robots are examples of great technology present today => 0.9944429973248587\n",
      "\t- all of us were singing in the concert => 0\n",
      "\t- we have launch campaigns to stop pollution and global warming => 0\n",
      "\n",
      "Concept 4:\n",
      "\t- the amount of pollution is increasing day by day => 1.852977324914452\n",
      "\t- the concert was just great => 0.10316082823817713\n",
      "\t- i love to see gordon ramsay cook => 0\n",
      "\t- google is introducing a new technology => 0.1587942790036928\n",
      "\t- ai robots are examples of great technology present today => 0\n",
      "\t- all of us were singing in the concert => 0.10316082823817713\n",
      "\t- we have launch campaigns to stop pollution and global warming => 0.40836291531122126\n"
     ]
    }
   ],
   "source": [
    "for concept_key in concept_words.keys():\n",
    "    \n",
    "    print('\\n' + concept_key + ':')\n",
    "    \n",
    "    for sentence in dataset:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        score = 0\n",
    "        for word in words:\n",
    "            for word_with_score in concept_words[concept_key]:\n",
    "                if word == word_with_score[0]:\n",
    "                    score += word_with_score[1]\n",
    "        \n",
    "        print('\\t- ' + sentence + ' => ' + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
